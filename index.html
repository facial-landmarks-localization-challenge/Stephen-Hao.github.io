<!DOCTYPE html>
<html lang="en" style="overflow: hidden; height: 100%;">

<head>
    <meta charset="utf-8">
    <title>Grand Challenge of 106-p Facial Landmark Localization</title>
    <link rel="stylesheet" href="src/css/jquery.fullPage.css">
    <link rel="stylesheet" href="src/css/ai-competition.css">
</head>

<body>
    <div class="navigation">
        <ul id="menu">
            <li class="logo"><img src="src/assets/images/logo3.png" /></li>
            <li data-menuanchor="index" class="active"><a href="#index">Home</a></li>
            <li data-menuanchor="introduction" class=""><a href="#introduction">Introduction</a></li>
            <li data-menuanchor="fashion-style" class=""><a href="#fashion-style">Challenge</a></li>
            <li data-menuanchor="prize" class=""><a href="#prize">Prize</a></li>
            <li data-menuanchor="comp-date" class=""><a href="#comp-date">Deadline </a></li>
            <li data-menuanchor="organizer" class=""><a href="#organizer">Coordinators</a></li>
            <li data-menuanchor="contact-us" class=""><a href="#contact-us">Contacts</a></li>
        </ul>
    </div>
    <div id="content_container">
        <div class="section fp-section fp-table active" data-anchor="index">
            <div class="fp-tableCell">
                

                        <h3 style="text-align:center">Grand Challenge of 106-p Facial Landmark Localization</h3>
                        <h5 style="text-align:center">ICME2019</h5>
              
                
                <a class="sign-btn" href="https://wj.qq.com/s/2777865/fa45">Click to sign up</a>
            </div>
            
        </div>
                <div class="section fp-section fp-table" data-anchor="introduction">
            <div class="container introduction-content">
               
                <ul class="introduction-list">
                    <li>
                        <p><b>Introduction</b></p>
                    </li>
                    <li>
                        <p>As the deep learning methods have been largely developed in facial landmark localization task, the requirements of practical applications are growing fast. However, for large poses and occlusion, the accuracy of localization  needs to be improved. Here, JD AI Research and NLPR, CASIA sincerely invited researchers and developers from academia and industry to participate in this competition and encourage further discussion on technical and application issues.
                        </p>
                    </li>
                    <li>
                        <p>&nbsp;</p>
                    </li>
                    <li>
                        <p><b>News</b></p>
                    </li>
                    <li>
                        <p>2018/11/16 - The competition has officially started and the training data has been released! Now, you can register for the competition to get training data.</p>
                        <p>2018/11/26 - The key rule: You can only use the data we provide for the competition, and you can't use external data.</p>
                        <p>2018/11/26 - We are very sorry that there are 45 wrong landmark .txt files in the dataset (world/china), please download the corrected data, you can replace the previous .txt files.<a href="https://github.com/facial-landmarks-localization-challenge/facial-landmarks-localization-challenge.github.io/blob/master/Corrected_data.zip"></p>
                    </li>
                </ul>
            </div>

        </div>
        
        
        <div class="section fp-section fp-table" data-anchor="fashion-style">
            <div class="container">
                <ul class="fashion-style-text">
                    <li>
                        <p>Facial landmark localization serves as a key step for many face applications, such as face recognition, emotion estimation and face reconstruction. The objective of facial landmark localization is to predict the coordinates of a set of pre-defined key points on human face. 106-key-point landmarks enable abundant geometric information for face analysis tasks. The purpose of this competition is to promote the development of research on face landmark localization, especially dealing with the complex situations, e.g. large face poses, extreme expressions and occlusions.
                        </p>
                    </li>
                </ul>
                <div class="btn-container">
                    <div class="detail-intro"><a href="https://github.com/facial-landmarks-localization-challenge/facial-landmarks-localization-challenge.github.io/blob/master/ICME2019_GC_facial_landmark_localization_proposal.docx">Details</a></div>
                    <div class="related-link"><a href="https://ibug.doc.ic.ac.uk/resources/300-W/">Related link</a></div>
                    <div class="sample-data"><a href="https://pan.baidu.com/s/1IYHHex5yPvwMzbIqepikUQ">Data(China)</a><img src="src/assets/images/download2.png" /></div>
                    <div class="sample-data"><a href="https://drive.google.com/file/d/125_iU9vDAhi_AFjRCYvPmkXkrpSeu8ik/view">Data(World)</a><img src="src/assets/images/download2.png" /></div>
                    <div class="ranking-detail"><a href=" ">Leaderboards</font></a></div>
                    <div class="sample-data"><a href=" ">Report</a></div>
                </div>
                <div class=""fashion-style-img">
                    <img src="src/assets/images/data12345678.png">
                </div>
            </div>
        </div>
        <div class="section fp-section fp-table prize-section" data-anchor="prize">
            <div class="container prize-list">
                <p class="comp-date">According to the final test results, the first prize, the second prize and the third prize will be established.</p>
                <div class="prize-bg prize-text">
                    <img src="src/assets/images/prize1.png">
                    <p>First prize</p>
                    <p>Cash, JD cloud voucher and Certificate</p>
                </div>
                <div class="prize-bg prize-text">
                    <img src="src/assets/images/prize2.png">
                    <p>Second prize</p>
                    <p>Cash, JD cloud voucher and Certificate</p>
                </div>
                <div class="prize-bg prize-text">
                    <img src="src/assets/images/prize3.png">
                    <p>Third prize</p>
                    <p>Cash and Certificate</p>
                </div>
            </div>
        </div>
        <div class="section fp-section fp-table" data-anchor="comp-date">
            <div class="container">
                <p class="comp-date">From now on, we start the competition registration and release sample data.</p>
                <table>
                    <tr bgcolor="#F5F7F9">
                        <td>2018/11/16</td>
                        <td>Challenge registration start</td>
                    </tr>
                    <tr>
                        <td>2018/12/1 - 2019/4/1</td>
                        <td>Test 1(Phase validation)</td>
                    </tr>
                    <tr bgcolor="#F5F7F9">
                        <td>2019/4/4-2019/4-8</td>
                        <td>Test 2(Phase final evaluation): Model&paper submission deadline</td>
                    </tr>
                    <tr>
                        <td>2019/4/22</td>
                        <td>Paper acceptance notification</td>
                    </tr>
                    <tr bgcolor="#F5F7F9">
                        <td>2019/4/22</td>
                        <td>Final evaluation results announcement</td>
                    </tr>
                    <tr>
                        <td>2019/4/29</td>
                        <td>Camera-ready paper submission deadline</td>
                    </tr>
                </table>
                <div class = "container tips">
                    Tips: You must register for the competition to get training data, and you are not allowed to use external data. The submission model must be TF, Pytorch, Caffe, Caffe2, and a detailed description(including preprocessing, etc.).
                    
                </div>
            </div>
        </div>
        <div class="section fp-section fp-table prize-section" data-anchor="organizer">
            <div class="container organizer-list">
                <div class="organizer-bg prize-text">
                    <img src="src/assets/images/shihailin.png">
                    <p>Dr. Hailin Shi</p>
                    <p>JD AI Platform and Research</p>
                </div>
                <div class="organizer-bg prize-text">
                    <img src="src/assets/images/wangxiaobo.jpg">
                    <p>Dr. Xiaobo Wang</p>
                    <p>JD AI Platform and Research</p>
                </div>
                <div class="organizer-bg prize-text">
                    <img src="src/assets/images/liuyinglu.jpg">
                    <p>Dr. Yinglu Liu</p>
                    <p>JD AI Platform and Research</p>
                </div>
                <div class="organizer-bg prize-text">
                    <img src="src/assets/images/zhuxiangyu.png">
                    <p>Dr. Xiangyu Zhu</p>
                    <p>Chinese Academy of Sciences</p>
                </div>
            </div>
        </div>
        <div class="section fp-section fp-table" data-anchor="contact-us">
            <div class="container contact-us">
                <p><b>Please send model or binary with a brief method description to Hao Shen at <span>shenhao5@jd.com</span></b></p>
                <p></p>
                <p>Ackownledge to the authors of these datasets:300W [1], LFPW [2], AFW [3], HELEN [4] and IBUG [5].
                <p>[1] C. Sagonas, G. Tzimiropoulos, S. Zafeiriou, and M. Pantic.300 Faces in-the-Wild Challenge: The first facial landmark localization Challenge. InInternational Conference onComputer Vision - Workshops (ICCVW), pages 397–403, 2013.</p>
                <p>[2] Belhumeur, P., Jacobs, D., Kriegman, D., Kumar, N.. ‘Localizing parts of faces using a consensus of exemplars’.  In Computer Vision and Pattern Recognition, CVPR. (2011).</p>
                <p>[3] X. Zhu, D. Ramanan.‘Face detection, pose estimation and landmark localization in the wild’, Computer Visionand Pattern Recognition (CVPR) Providence, Rhode Island, June 2012.</p>
                <p>[4] Vuong Le, Jonathan Brandt, Zhe Lin, Lubomir Boudev, Thomas S. Huang. ‘Interactive Facial Feature Localization’, ECCV2012.</p> 
                <p>[5] C. Sagonas, G. Tzimiropoulos, S. Zafeiriou, and M. Pantic. A semi-automatic methodology for facial landmark annotation. In CVPR, 2013.</p> 
                <img src="src/assets/images/logo7.PNG">
            </div>
            <div class="footer">
                <img src="src/assets/images/logo.png" />
                <div>Copyright© JD.com</div>
            </div>
        </div>
    </div>

    <script src="src/js/libs/jquery-1.9.1.min.js"></script>
    <script src="src/js/libs/jquery.fullpage.min.js"></script>
    <script src="src/js/ai-competition.js"></script>
</body>

</html>
